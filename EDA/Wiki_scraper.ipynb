{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:09.246564Z",
     "start_time": "2018-08-28T19:44:09.114394Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import lxml.etree\n",
    "import urllib\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "from textstat.textstat import textstat\n",
    "from gensim.corpora import wikicorpus\n",
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from typing import List, Tuple, Dict, Any, Generator, Iterable\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "# Make it pretty\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:09.799341Z",
     "start_time": "2018-08-28T19:44:09.740048Z"
    }
   },
   "outputs": [],
   "source": [
    "def browse_to_category(browser, category):\n",
    "    \"\"\" Use browser to get Wikipedia Category page.\"\"\"\n",
    "    url = 'https://en.wikipedia.org/wiki/Category:' + category\n",
    "    browser.get(url)\n",
    "\n",
    "def get_category_title(browser):\n",
    "    \"\"\" Use css tag 'h1.firstHeading' to find the main category.\"\"\"\n",
    "    headline = browser.find_elements_by_css_selector('h1.firstHeading')\n",
    "    title = [text.text for text in headline]\n",
    "    return title[0].partition('Category:')[2]\n",
    "\n",
    "def get_sub_categories(browser):\n",
    "    \"\"\" Use css tag 'a.CategoryTreeLabel' to find the sub-categories.\"\"\"\n",
    "    subs = browser.find_elements_by_css_selector('a.CategoryTreeLabel')\n",
    "    return [category.text for category in subs]\n",
    "\n",
    "def click_to_sub_category_page(browser, page):\n",
    "    \"\"\" Click a sub_category and be taken to its pages\"\"\"\n",
    "    browser.find_element_by_link_text(page).click()\n",
    "\n",
    "def filter_pages(pages):\n",
    "    for page in pages:\n",
    "        if len(page) < 2:\n",
    "            pages.remove(page)\n",
    "    return pages\n",
    "\n",
    "def get_wiki_xml(title):\n",
    "    title = title\n",
    "    params = { \"format\":\"xml\", \"action\":\"query\", \"prop\":\"revisions\", \"rvprop\":\"timestamp|user|comment|content\" }\n",
    "    params[\"titles\"] = \"API|%s\" % urllib.parse.quote(title.encode(\"utf8\"))\n",
    "    qs = \"&\".join(\"%s=%s\" % (k, v)  for k, v in params.items())\n",
    "    url = \"http://en.wikipedia.org/w/api.php?%s\" % qs\n",
    "    tree = lxml.etree.parse(urllib.request.urlopen(url))\n",
    "    revs = tree.xpath('//rev')\n",
    "    return (revs[-1].text)\n",
    "\n",
    "def clean_wiki_markup(raw_article):\n",
    "    semi_cleaned_article = wikicorpus.filter_wiki(raw_article)\n",
    "    cleaned_article = semi_cleaned_article.replace(\"\\n\", \"\").replace(\"\\'\", \"\").replace(\"()\", \"\").replace(\"=\", \"\").replace(\"|alt\",\"\").replace(\"\\xa0\",\"\")\n",
    "    return cleaned_article\n",
    "def find_num_categories(raw_article):\n",
    "    return raw_article.count(\"[[Category:\")\n",
    "def find_num_images(raw_article):\n",
    "    return raw_article.count(\"[[Image:\")\n",
    "def find_num_ISBN(raw_article):\n",
    "    return raw_article.count(\"ISBN\")\n",
    "def find_num_references(raw_article):\n",
    "    return raw_article.count(\"</ref>\")\n",
    "def find_article_length(cleaned_article):\n",
    "    return len(cleaned_article)\n",
    "def find_num_difficult_words(cleaned_article):\n",
    "    return textstat.difficult_words(cleaned_article)\n",
    "def find_dale_chall_readability_score(cleaned_article):\n",
    "    return textstat.dale_chall_readability_score(cleaned_article)\n",
    "def find_automated_readability_index(cleaned_article):\n",
    "    return textstat.automated_readability_index(cleaned_article)\n",
    "def find_linsear_write_formula(cleaned_article):\n",
    "    return textstat.linsear_write_formula(cleaned_article)\n",
    "def find_gunning_fog_index(cleaned_article):\n",
    "    return textstat.gunning_fog(cleaned_article)\n",
    "def find_syllable_count(cleaned_article):\n",
    "    return textstat.syllable_count(cleaned_article)\n",
    "def find_lexicon_count(cleaned_article):\n",
    "    return textstat.lexicon_count(cleaned_article, removepunct=True)\n",
    "def find_sentence_count(cleaned_article):\n",
    "    return textstat.sentence_count(cleaned_article)\n",
    "def find_smog_index(cleaned_article):\n",
    "    return textstat.smog_index(cleaned_article)\n",
    "def find_num_web_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite web\")\n",
    "def find_num_book_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite book\")\n",
    "def find_num_news_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite news\")\n",
    "def find_num_quotes(raw_article):\n",
    "    return raw_article.count(\"quote=\")\n",
    "def find_num_h3_headers(raw_article):\n",
    "    return raw_article.count(\"\\n===\")\n",
    "def find_num_internal_links(raw_article):\n",
    "    return (raw_article.count(\"[[\") // 2)\n",
    "def find_num_h2_headers(raw_article):\n",
    "    return (raw_article.count(\"\\n==\") - find_num_h3_headers(raw_article))\n",
    "def find_num_note_tags(raw_article):\n",
    "    return raw_article.count(\"{{note\")\n",
    "def find_num_bullet_points(raw_article):\n",
    "    return (raw_article.count(\"*\"))\n",
    "def find_num_underlines(raw_article):\n",
    "    return (raw_article.count(\"<u>\"))\n",
    "def find_num_journal_citations(raw_article):\n",
    "    return (raw_article.count(\"{{cite journal\"))\n",
    "def find_num_about_links(raw_article):\n",
    "    return (raw_article.count(\"{{About\"))\n",
    "def find_num_wikitables(raw_article):\n",
    "    return (raw_article.count('class=\"wikitable'))\n",
    "def find_num_footnotes(raw_article):\n",
    "    return raw_article.count(\"{{\")\n",
    "def find_infobox(raw_article):\n",
    "    return int('{{Infobox' in raw_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Start-to-finish:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Go to wikipedia category page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:20.933715Z",
     "start_time": "2018-08-28T19:44:18.865772Z"
    }
   },
   "outputs": [],
   "source": [
    "category = 'machine_learning'\n",
    "browser = Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:22.590550Z",
     "start_time": "2018-08-28T19:44:21.676941Z"
    }
   },
   "outputs": [],
   "source": [
    "browse_to_category(browser, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Grab Overarching Category title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:23.105274Z",
     "start_time": "2018-08-28T19:44:23.031459Z"
    }
   },
   "outputs": [],
   "source": [
    "Overarching_title = get_category_title(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:23.360911Z",
     "start_time": "2018-08-28T19:44:23.317891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Overarching_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Grab Subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:24.698439Z",
     "start_time": "2018-08-28T19:44:24.235091Z"
    }
   },
   "outputs": [],
   "source": [
    "subs = get_sub_categories(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:24.746321Z",
     "start_time": "2018-08-28T19:44:24.700509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Applied machine learning',\n",
       " 'Artificial neural networks',\n",
       " 'Bayesian networks',\n",
       " 'Classification algorithms',\n",
       " 'Cluster analysis',\n",
       " 'Computational learning theory',\n",
       " 'Artificial intelligence conferences',\n",
       " 'Signal processing conferences',\n",
       " 'Data mining and machine learning software',\n",
       " 'Datasets in machine learning',\n",
       " 'Dimension reduction',\n",
       " 'Ensemble learning',\n",
       " 'Evolutionary algorithms',\n",
       " 'Genetic programming',\n",
       " 'Inductive logic programming',\n",
       " 'Kernel methods for machine learning',\n",
       " 'Latent variable models',\n",
       " 'Learning in computer vision',\n",
       " 'Log-linear models',\n",
       " 'Loss functions',\n",
       " 'Machine learning algorithms',\n",
       " 'Machine learning portal',\n",
       " 'Machine learning task',\n",
       " 'Markov models',\n",
       " 'Machine learning researchers',\n",
       " 'Semisupervised learning',\n",
       " 'Statistical natural language processing',\n",
       " 'Structured prediction',\n",
       " 'Supervised learning',\n",
       " 'Support vector machines',\n",
       " 'Unsupervised learning']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Grab Subcategory information and store in MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:44:50.990035Z",
     "start_time": "2018-08-28T19:44:50.947464Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "new_db = client['new_db']\n",
    "collection = new_db['new_db']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over sub-categories and add their subsquent pages in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:49:37.726722Z",
     "start_time": "2018-08-28T19:44:57.776437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied machine learning\n",
      "Artificial neural networks\n",
      "Bayesian networks\n",
      "Classification algorithms\n",
      "Cluster analysis\n",
      "Computational learning theory\n",
      "Artificial intelligence conferences\n",
      "Signal processing conferences\n",
      "Data mining and machine learning software\n",
      "Datasets in machine learning\n",
      "Dimension reduction\n",
      "Ensemble learning\n",
      "Evolutionary algorithms\n",
      "Genetic programming\n",
      "Inductive logic programming\n",
      "Kernel methods for machine learning\n",
      "Latent variable models\n",
      "Learning in computer vision\n",
      "Log-linear models\n",
      "Loss functions\n",
      "Machine learning algorithms\n",
      "Machine learning portal\n",
      "Machine learning task\n",
      "Markov models\n",
      "Machine learning researchers\n",
      "Semisupervised learning\n",
      "Statistical natural language processing\n",
      "Structured prediction\n",
      "Supervised learning\n",
      "Support vector machines\n",
      "Unsupervised learning\n"
     ]
    }
   ],
   "source": [
    "for sub_cat in subs:\n",
    "    browse_to_category(browser, category)\n",
    "    cick_to_sub_category_page(sub_cat)\n",
    "    title = get_category_title(browser)\n",
    "    print(title)\n",
    "    try:\n",
    "        w = browser.find_element_by_class_name('mw-category')\n",
    "        pages = filter_pages(w.text.split('\\n'))\n",
    "        for page in pages:\n",
    "            post = {'category': title,\n",
    "                'page': page,\n",
    "                'text' : get_wiki_xml(page)}\n",
    "            posts = new_db.posts\n",
    "            post = posts.insert_one(post)\n",
    "    except NoSuchElementException:\n",
    "        w = browser.find_elements_by_class_name('mw-content-ltr')\n",
    "        pages = filter_pages(w[0].text.split('\\n'))[2:]\n",
    "        for page in pages:\n",
    "            post = {'category': title,\n",
    "                'page': page,\n",
    "                'text' : get_wiki_xml(page)}\n",
    "            posts = new_db.posts\n",
    "            post = posts.insert_one(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Convert MongoDB to pandas DF and clean/transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:50:04.004140Z",
     "start_time": "2018-08-28T19:50:03.580988Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(posts.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:50:16.416258Z",
     "start_time": "2018-08-28T19:50:16.366107Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(columns='_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:50:27.895838Z",
     "start_time": "2018-08-28T19:50:27.764039Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data['text'] != \"\"]\n",
    "data = data[data['text'].str.contains(\"#redirect\") == False]\n",
    "data = data[data['text'].str.contains(\"may refer to:\\n\\n*\") == False]\n",
    "data = data[data['text'].str.contains(\"can refer to:\\n\") == False]\n",
    "data = data[data['text'].str.contains(\"could refer to:\\n\") == False]\n",
    "data = data[data['text'].str.contains(\"#REDIRECT\") == False]\n",
    "data = data[data['text'].str.contains(\"== Matches ==\\n:\") == False]\n",
    "data = data[data['text'].str.contains(\"{{underconstruction\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:52:09.986576Z",
     "start_time": "2018-08-28T19:50:31.539376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(DCRS): Word Count is zero cannot divide\n",
      "Error(ARI) : Sentence count is zero, cannot divide\n",
      "Error(GF): Word Count is Zero, cannot divide\n"
     ]
    }
   ],
   "source": [
    "data['cleaned_text'] = data['text'].apply(clean_wiki_markup)\n",
    "data['num_web_citations'] = data['text'].apply(find_num_web_citations)\n",
    "data['num_book_citations'] = data['text'].apply(find_num_book_citations)\n",
    "data['num_news_citations'] = data['text'].apply(find_num_news_citations)\n",
    "data['num_quotes'] = data['text'].apply(find_num_quotes)\n",
    "data['num_h3_headers'] = data['text'].apply(find_num_h3_headers)\n",
    "data['num_internal_links'] = data['text'].apply(find_num_internal_links)\n",
    "data['num_h2_headers'] = data['text'].apply(find_num_h2_headers)\n",
    "data['has_infobox'] = data['text'].str.contains('{{Infobox').astype(int)\n",
    "data['num_categories'] = data['text'].apply(find_num_categories)\n",
    "data['num_images'] = data['text'].apply(find_num_images)\n",
    "data['num_ISBN'] = data['text'].apply(find_num_ISBN)\n",
    "data['num_references'] = data['text'].apply(find_num_references)\n",
    "data['article_length'] = data['text'].apply(find_article_length)\n",
    "data['num_difficult_words'] = data['cleaned_text'].apply(find_num_difficult_words)\n",
    "data['dale_chall_readability_score'] = data['cleaned_text'].apply(find_dale_chall_readability_score)\n",
    "data['readability_index'] = data['cleaned_text'].apply(find_automated_readability_index)\n",
    "data['linsear_write_formula'] = data['cleaned_text'].apply(find_linsear_write_formula)\n",
    "data['gunning_fog_index'] = data['cleaned_text'].apply(find_gunning_fog_index)\n",
    "data['smog_index'] = data['cleaned_text'].apply(find_smog_index)\n",
    "data['syllable_count'] = data['cleaned_text'].apply(find_syllable_count)\n",
    "data['lexicon_count'] = data['cleaned_text'].apply(find_lexicon_count)\n",
    "data['sentence_count'] = data['cleaned_text'].apply(find_sentence_count)\n",
    "data['num_footnotes'] = data['text'].apply(find_num_footnotes)\n",
    "data['num_note_tags'] = data['text'].apply(find_num_note_tags)\n",
    "data['num_underlines'] = data['text'].apply(find_num_underlines)\n",
    "data['num_journal_citations'] = data['text'].apply(find_num_journal_citations)\n",
    "data['num_about_links'] = data['text'].apply(find_num_about_links)\n",
    "data['num_wikitables'] = data['text'].apply(find_num_wikitables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:53:01.571701Z",
     "start_time": "2018-08-28T19:53:01.520071Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Pickle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T21:53:50.789497Z",
     "start_time": "2018-08-25T21:53:50.684662Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_pickle('Machine_Learning_Category_Wikipedia.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Split data into corrext input (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:53:04.213836Z",
     "start_time": "2018-08-28T19:53:04.165414Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.loc[:, ['has_infobox','num_categories','num_images','num_ISBN','num_references','article_length',\n",
    "                'num_difficult_words','dale_chall_readability_score','readability_index','linsear_write_formula',\n",
    "                'gunning_fog_index', 'num_web_citations','num_book_citations','num_news_citations',\n",
    "                'num_quotes','num_h3_headers','num_internal_links', 'num_h2_headers', 'syllable_count',\n",
    "                'lexicon_count', 'sentence_count','num_footnotes', 'num_note_tags', 'num_underlines', 'num_journal_citations',\n",
    "                'num_about_links', 'num_wikitables', 'smog_index']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:53:12.053883Z",
     "start_time": "2018-08-28T19:53:11.647204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "rf_model = pickle.load(open('../src/random_forest_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:53:14.196207Z",
     "start_time": "2018-08-28T19:53:14.129764Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = rf_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:53:15.918029Z",
     "start_time": "2018-08-28T19:53:15.877991Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Predicted_Quality'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:53:36.803785Z",
     "start_time": "2018-08-28T19:53:36.763568Z"
    }
   },
   "outputs": [],
   "source": [
    "Cat_page_df = data.loc[:, ['category', 'page', 'Predicted_Quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:55:17.615118Z",
     "start_time": "2018-08-28T19:55:17.575262Z"
    }
   },
   "outputs": [],
   "source": [
    "Cat_groups = Cat_page_df.groupby(by='category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T12:36:36.938369Z",
     "start_time": "2018-08-26T12:36:36.894202Z"
    }
   },
   "outputs": [],
   "source": [
    "ML_page_predictions = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T12:37:35.907580Z",
     "start_time": "2018-08-26T12:37:35.569721Z"
    }
   },
   "outputs": [],
   "source": [
    "ML_page_predictions.to_pickle('ML_page_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:48:58.457751Z",
     "start_time": "2018-08-28T17:48:58.414593Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wiki_category_quality(category):\n",
    "    category = category\n",
    "    browser = Chrome()\n",
    "    browse_to_category(browser, category)\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    category_db = client['category_db']\n",
    "    collection = dogs_db['category_db']\n",
    "    subs = get_sub_categories(browser)\n",
    "    for sub_cat in subs:\n",
    "        browse_to_category(browser, category)\n",
    "        time.sleep(2)\n",
    "        click_to_sub_category_page(browser, sub_cat)\n",
    "        title = get_category_title(browser)\n",
    "        try:\n",
    "            w = browser.find_element_by_class_name('mw-category')\n",
    "            pages = filter_pages(w.text.split('\\n'))\n",
    "            for page in pages:\n",
    "                post = {'category': title,\n",
    "                    'page': page,\n",
    "                    'text' : get_wiki_xml(page)}\n",
    "                posts = dogs_db.posts\n",
    "                post = posts.insert_one(post)\n",
    "        except NoSuchElementException:\n",
    "            w = browser.find_elements_by_class_name('mw-content-ltr')\n",
    "            pages = filter_pages(w[0].text.split('\\n'))[2:]\n",
    "            for page in pages:\n",
    "                post = {'category': title,\n",
    "                    'page': page,\n",
    "                    'text' : get_wiki_xml(page)}\n",
    "                posts = dogs_db.posts\n",
    "                post = posts.insert_one(post)\n",
    "    data = pd.DataFrame(list(posts.find()))\n",
    "    data.drop(columns='_id',inplace=True)\n",
    "    data = data[data['text'] != \"\"]\n",
    "    data = data[data['text'].str.contains(\"#redirect\") == False]\n",
    "    data = data[data['text'].str.contains(\"may refer to:\\n\\n*\") == False]\n",
    "    data = data[data['text'].str.contains(\"can refer to:\\n\") == False]\n",
    "    data = data[data['text'].str.contains(\"could refer to:\\n\") == False]\n",
    "    data = data[data['text'].str.contains(\"#REDIRECT\") == False]\n",
    "    data = data[data['text'].str.contains(\"== Matches ==\\n:\") == False]\n",
    "    data = data[data['text'].str.contains(\"{{underconstruction\") == False]\n",
    "    data['cleaned_text'] = data['text'].apply(clean_wiki_markup)\n",
    "    data['num_web_citations'] = data['text'].apply(find_num_web_citations)\n",
    "    data['num_book_citations'] = data['text'].apply(find_num_book_citations)\n",
    "    data['num_news_citations'] = data['text'].apply(find_num_news_citations)\n",
    "    data['num_quotes'] = data['text'].apply(find_num_quotes)\n",
    "    data['num_h3_headers'] = data['text'].apply(find_num_h3_headers)\n",
    "    data['num_internal_links'] = data['text'].apply(find_num_internal_links)\n",
    "    data['num_h2_headers'] = data['text'].apply(find_num_h2_headers)\n",
    "    data['has_infobox'] = data['text'].str.contains('{{Infobox').astype(int)\n",
    "    data['num_categories'] = data['text'].apply(find_num_categories)\n",
    "    data['num_images'] = data['text'].apply(find_num_images)\n",
    "    data['num_ISBN'] = data['text'].apply(find_num_ISBN)\n",
    "    data['num_references'] = data['text'].apply(find_num_references)\n",
    "    data['article_length'] = data['text'].apply(find_article_length)\n",
    "    data['num_difficult_words'] = data['cleaned_text'].apply(find_num_difficult_words)\n",
    "    data['dale_chall_readability_score'] = data['cleaned_text'].apply(find_dale_chall_readability_score)\n",
    "    data['readability_index'] = data['cleaned_text'].apply(find_automated_readability_index)\n",
    "    data['linsear_write_formula'] = data['cleaned_text'].apply(find_linsear_write_formula)\n",
    "    data['gunning_fog_index'] = data['cleaned_text'].apply(find_gunning_fog_index)\n",
    "    data['smog_index'] = data['cleaned_text'].apply(find_smog_index)\n",
    "    data['syllable_count'] = data['cleaned_text'].apply(find_syllable_count)\n",
    "    data['lexicon_count'] = data['cleaned_text'].apply(find_lexicon_count)\n",
    "    data['sentence_count'] = data['cleaned_text'].apply(find_sentence_count)\n",
    "    data['num_footnotes'] = data['text'].apply(find_num_footnotes)\n",
    "    data['num_note_tags'] = data['text'].apply(find_num_note_tags)\n",
    "    data['num_underlines'] = data['text'].apply(find_num_underlines)\n",
    "    data['num_journal_citations'] = data['text'].apply(find_num_journal_citations)\n",
    "    data['num_about_links'] = data['text'].apply(find_num_about_links)\n",
    "    data['num_wikitables'] = data['text'].apply(find_num_wikitables)\n",
    "    data.dropna(inplace=True)\n",
    "    X = data.loc[:, ['has_infobox','num_categories','num_images','num_ISBN','num_references','article_length',\n",
    "                'num_difficult_words','dale_chall_readability_score','readability_index','linsear_write_formula',\n",
    "                'gunning_fog_index', 'num_web_citations','num_book_citations','num_news_citations',\n",
    "                'num_quotes','num_h3_headers','num_internal_links', 'num_h2_headers', 'syllable_count',\n",
    "                'lexicon_count', 'sentence_count','num_footnotes', 'num_note_tags', 'num_underlines', 'num_journal_citations',\n",
    "                'num_about_links', 'num_wikitables', 'smog_index']].values\n",
    "    predictions = rf_model.predict(X)\n",
    "    data['Predicted_Quality'] = predictions\n",
    "    Cat_page_df = data.loc[:, ['category', 'page', 'Predicted_Quality']]\n",
    "    return Cat_page_df.groupby(by='category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:42:24.323800Z",
     "start_time": "2018-08-28T19:42:24.284206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:51:00.489459Z",
     "start_time": "2018-08-28T17:49:26.636827Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "get_wiki_category_quality('machine_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:41:54.813226Z",
     "start_time": "2018-08-27T17:41:54.518319Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data = pickle.load( open( \"Machine_Learning_Category_Wikipedia.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:56:35.746833Z",
     "start_time": "2018-08-28T19:56:35.702776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Quality</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.885312</td>\n",
       "      <td>Applied machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.528246</td>\n",
       "      <td>Artificial intelligence conferences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.668835</td>\n",
       "      <td>Artificial neural networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.622311</td>\n",
       "      <td>Bayesian networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.957163</td>\n",
       "      <td>Classification algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.925219</td>\n",
       "      <td>Cluster analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.587266</td>\n",
       "      <td>Computational learning theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.669472</td>\n",
       "      <td>Data mining and machine learning software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.793419</td>\n",
       "      <td>Datasets in machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.962699</td>\n",
       "      <td>Dimension reduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.959181</td>\n",
       "      <td>Ensemble learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.861621</td>\n",
       "      <td>Evolutionary algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.556965</td>\n",
       "      <td>Genetic programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.501882</td>\n",
       "      <td>Inductive logic programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.811093</td>\n",
       "      <td>Kernel methods for machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.277773</td>\n",
       "      <td>Latent variable models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.051726</td>\n",
       "      <td>Learning in computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.322464</td>\n",
       "      <td>Log-linear models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.752388</td>\n",
       "      <td>Loss functions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.633258</td>\n",
       "      <td>Machine learning algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.213381</td>\n",
       "      <td>Machine learning portal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.544431</td>\n",
       "      <td>Machine learning researchers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.695210</td>\n",
       "      <td>Machine learning task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.176127</td>\n",
       "      <td>Markov models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.865635</td>\n",
       "      <td>Semisupervised learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.705629</td>\n",
       "      <td>Signal processing conferences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.769714</td>\n",
       "      <td>Statistical natural language processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.716344</td>\n",
       "      <td>Structured prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.881246</td>\n",
       "      <td>Supervised learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.912011</td>\n",
       "      <td>Support vector machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.530980</td>\n",
       "      <td>Unsupervised learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted_Quality                                   category\n",
       "0            1.885312                   Applied machine learning\n",
       "1            1.528246        Artificial intelligence conferences\n",
       "2            1.668835                 Artificial neural networks\n",
       "3            1.622311                          Bayesian networks\n",
       "4            1.957163                  Classification algorithms\n",
       "5            1.925219                           Cluster analysis\n",
       "6            1.587266              Computational learning theory\n",
       "7            1.669472  Data mining and machine learning software\n",
       "8            1.793419               Datasets in machine learning\n",
       "9            1.962699                        Dimension reduction\n",
       "10           1.959181                          Ensemble learning\n",
       "11           1.861621                    Evolutionary algorithms\n",
       "12           1.556965                        Genetic programming\n",
       "13           1.501882                Inductive logic programming\n",
       "14           1.811093        Kernel methods for machine learning\n",
       "15           2.277773                     Latent variable models\n",
       "16           2.051726                Learning in computer vision\n",
       "17           0.322464                          Log-linear models\n",
       "18           1.752388                             Loss functions\n",
       "19           1.633258                Machine learning algorithms\n",
       "20           0.213381                    Machine learning portal\n",
       "21           1.544431               Machine learning researchers\n",
       "22           2.695210                      Machine learning task\n",
       "23           2.176127                              Markov models\n",
       "24           2.865635                    Semisupervised learning\n",
       "25           1.705629              Signal processing conferences\n",
       "26           1.769714    Statistical natural language processing\n",
       "27           1.716344                      Structured prediction\n",
       "28           2.881246                        Supervised learning\n",
       "29           1.912011                    Support vector machines\n",
       "30           2.530980                      Unsupervised learning"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cat_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:44:41.720292Z",
     "start_time": "2018-08-27T21:44:41.514205Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data['category'] = ml_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:56:32.460889Z",
     "start_time": "2018-08-28T19:56:32.422037Z"
    }
   },
   "outputs": [],
   "source": [
    "Cat_groups.index = list(range(len(Cat_groups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T20:11:34.683117Z",
     "start_time": "2018-08-28T20:11:34.641981Z"
    }
   },
   "outputs": [],
   "source": [
    "Cat_groups.to_pickle('ML_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:47:55.262431Z",
     "start_time": "2018-08-27T21:47:55.213383Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, d in ml_data.iterrows():\n",
    "    print(d['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T19:42:59.625009Z",
     "start_time": "2018-08-28T19:42:59.551761Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data = pickle.load(open('ML_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T20:11:26.359311Z",
     "start_time": "2018-08-28T20:11:26.311325Z"
    }
   },
   "outputs": [],
   "source": [
    "Cat_groups.Predicted_Quality = Cat_groups.Predicted_Quality.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T20:14:36.795708Z",
     "start_time": "2018-08-28T20:14:36.749712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted_Quality                        1.89\n",
      "category             Applied machine learning\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i, j in Cat_groups.iterrows():\n",
    "    print(j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
