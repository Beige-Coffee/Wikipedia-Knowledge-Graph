{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:45:06.474035Z",
     "start_time": "2018-08-28T17:45:03.012868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/austin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import lxml.etree\n",
    "import urllib\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "from textstat.textstat import textstat\n",
    "from gensim.corpora import wikicorpus\n",
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from typing import List, Tuple, Dict, Any, Generator, Iterable\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "# Make it pretty\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:49:21.821814Z",
     "start_time": "2018-08-28T17:49:21.772171Z"
    }
   },
   "outputs": [],
   "source": [
    "def browse_to_category(browser, category):\n",
    "    \"\"\" Use browser to get Wikipedia Category page.\"\"\"\n",
    "    url = 'https://en.wikipedia.org/wiki/Category:' + category\n",
    "    browser.get(url)\n",
    "\n",
    "def get_category_title(browser):\n",
    "    \"\"\" Use css tag 'h1.firstHeading' to find the main category.\"\"\"\n",
    "    headline = browser.find_elements_by_css_selector('h1.firstHeading')\n",
    "    title = [text.text for text in headline]\n",
    "    return title[0].partition('Category:')[2]\n",
    "\n",
    "def get_sub_categories(browser):\n",
    "    \"\"\" Use css tag 'a.CategoryTreeLabel' to find the sub-categories.\"\"\"\n",
    "    subs = browser.find_elements_by_css_selector('a.CategoryTreeLabel')\n",
    "    return [category.text for category in subs]\n",
    "\n",
    "def click_to_sub_category_page(browser, page):\n",
    "    \"\"\" Click a sub_category and be taken to its pages\"\"\"\n",
    "    browser.find_element_by_link_text(page).click()\n",
    "\n",
    "def filter_pages(pages):\n",
    "    for page in pages:\n",
    "        if len(page) < 2:\n",
    "            pages.remove(page)\n",
    "    return pages\n",
    "\n",
    "def get_wiki_xml(title):\n",
    "    title = title\n",
    "    params = { \"format\":\"xml\", \"action\":\"query\", \"prop\":\"revisions\", \"rvprop\":\"timestamp|user|comment|content\" }\n",
    "    params[\"titles\"] = \"API|%s\" % urllib.parse.quote(title.encode(\"utf8\"))\n",
    "    qs = \"&\".join(\"%s=%s\" % (k, v)  for k, v in params.items())\n",
    "    url = \"http://en.wikipedia.org/w/api.php?%s\" % qs\n",
    "    tree = lxml.etree.parse(urllib.request.urlopen(url))\n",
    "    revs = tree.xpath('//rev')\n",
    "    return (revs[-1].text)\n",
    "\n",
    "def clean_wiki_markup(raw_article):\n",
    "    semi_cleaned_article = wikicorpus.filter_wiki(raw_article)\n",
    "    cleaned_article = semi_cleaned_article.replace(\"\\n\", \"\").replace(\"\\'\", \"\").replace(\"()\", \"\").replace(\"=\", \"\").replace(\"|alt\",\"\").replace(\"\\xa0\",\"\")\n",
    "    return cleaned_article\n",
    "def find_num_categories(raw_article):\n",
    "    return raw_article.count(\"[[Category:\")\n",
    "def find_num_images(raw_article):\n",
    "    return raw_article.count(\"[[Image:\")\n",
    "def find_num_ISBN(raw_article):\n",
    "    return raw_article.count(\"ISBN\")\n",
    "def find_num_references(raw_article):\n",
    "    return raw_article.count(\"</ref>\")\n",
    "def find_article_length(cleaned_article):\n",
    "    return len(cleaned_article)\n",
    "def find_num_difficult_words(cleaned_article):\n",
    "    return textstat.difficult_words(cleaned_article)\n",
    "def find_dale_chall_readability_score(cleaned_article):\n",
    "    return textstat.dale_chall_readability_score(cleaned_article)\n",
    "def find_automated_readability_index(cleaned_article):\n",
    "    return textstat.automated_readability_index(cleaned_article)\n",
    "def find_linsear_write_formula(cleaned_article):\n",
    "    return textstat.linsear_write_formula(cleaned_article)\n",
    "def find_gunning_fog_index(cleaned_article):\n",
    "    return textstat.gunning_fog(cleaned_article)\n",
    "def find_syllable_count(cleaned_article):\n",
    "    return textstat.syllable_count(cleaned_article)\n",
    "def find_lexicon_count(cleaned_article):\n",
    "    return textstat.lexicon_count(cleaned_article, removepunct=True)\n",
    "def find_sentence_count(cleaned_article):\n",
    "    return textstat.sentence_count(cleaned_article)\n",
    "def find_smog_index(cleaned_article):\n",
    "    return textstat.smog_index(cleaned_article)\n",
    "def find_num_web_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite web\")\n",
    "def find_num_book_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite book\")\n",
    "def find_num_news_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite news\")\n",
    "def find_num_quotes(raw_article):\n",
    "    return raw_article.count(\"quote=\")\n",
    "def find_num_h3_headers(raw_article):\n",
    "    return raw_article.count(\"\\n===\")\n",
    "def find_num_internal_links(raw_article):\n",
    "    return (raw_article.count(\"[[\") // 2)\n",
    "def find_num_h2_headers(raw_article):\n",
    "    return (raw_article.count(\"\\n==\") - find_num_h3_headers(raw_article))\n",
    "def find_num_note_tags(raw_article):\n",
    "    return raw_article.count(\"{{note\")\n",
    "def find_num_bullet_points(raw_article):\n",
    "    return (raw_article.count(\"*\"))\n",
    "def find_num_underlines(raw_article):\n",
    "    return (raw_article.count(\"<u>\"))\n",
    "def find_num_journal_citations(raw_article):\n",
    "    return (raw_article.count(\"{{cite journal\"))\n",
    "def find_num_about_links(raw_article):\n",
    "    return (raw_article.count(\"{{About\"))\n",
    "def find_num_wikitables(raw_article):\n",
    "    return (raw_article.count('class=\"wikitable'))\n",
    "def find_num_footnotes(raw_article):\n",
    "    return raw_article.count(\"{{\")\n",
    "def find_infobox(raw_article):\n",
    "    return int('{{Infobox' in raw_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Start-to-finish:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Go to wikipedia category page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:39:56.008432Z",
     "start_time": "2018-08-28T17:39:54.397864Z"
    }
   },
   "outputs": [],
   "source": [
    "category = 'Dogs'\n",
    "browser = Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:40:02.991670Z",
     "start_time": "2018-08-28T17:40:02.133550Z"
    }
   },
   "outputs": [],
   "source": [
    "browse_to_category(browser, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Grab Overarching Category title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:40:11.140920Z",
     "start_time": "2018-08-28T17:40:11.064582Z"
    }
   },
   "outputs": [],
   "source": [
    "Overarching_title = get_category_title(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:40:11.683716Z",
     "start_time": "2018-08-28T17:40:11.630632Z"
    }
   },
   "outputs": [],
   "source": [
    "Overarching_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Grab Subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:40:16.915445Z",
     "start_time": "2018-08-28T17:40:16.524360Z"
    }
   },
   "outputs": [],
   "source": [
    "subs = get_sub_categories(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:40:18.286635Z",
     "start_time": "2018-08-28T17:40:18.229044Z"
    }
   },
   "outputs": [],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Grab Subcategory information and store in MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:45:50.655940Z",
     "start_time": "2018-08-28T17:45:50.619653Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "dogs_db = client['dogs_db']\n",
    "collection = dogs_db['dogs_db']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over sub-categories and add their subsquent pages in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:20:53.183312Z",
     "start_time": "2018-08-27T17:14:57.790131Z"
    }
   },
   "outputs": [],
   "source": [
    "for sub_cat in subs:\n",
    "    browse_to_category(browser, category)\n",
    "    cick_to_sub_category_page(sub_cat)\n",
    "    title = get_category_title(browser)\n",
    "    print(title)\n",
    "    try:\n",
    "        w = browser.find_element_by_class_name('mw-category')\n",
    "        pages = filter_pages(w.text.split('\\n'))\n",
    "        for page in pages:\n",
    "            post = {'category': title,\n",
    "                'page': page,\n",
    "                'text' : get_wiki_xml(page)}\n",
    "            posts = Machine_Learning_db.posts\n",
    "            post = posts.insert_one(post)\n",
    "    except NoSuchElementException:\n",
    "        w = browser.find_elements_by_class_name('mw-content-ltr')\n",
    "        pages = filter_pages(w[0].text.split('\\n'))[2:]\n",
    "        for page in pages:\n",
    "            post = {'category': title,\n",
    "                'page': page,\n",
    "                'text' : get_wiki_xml(page)}\n",
    "            posts = dogs_db.posts\n",
    "            post = posts.insert_one(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Convert MongoDB to pandas DF and clean/transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:24:18.216967Z",
     "start_time": "2018-08-27T17:24:17.377886Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(posts.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:24:19.831812Z",
     "start_time": "2018-08-27T17:24:19.765581Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(columns='_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:26:18.143849Z",
     "start_time": "2018-08-27T17:26:18.105405Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[1010:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:26:19.384853Z",
     "start_time": "2018-08-27T17:26:19.233809Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data['text'] != \"\"]\n",
    "data = data[data['text'].str.contains(\"#redirect\") == False]\n",
    "data = data[data['text'].str.contains(\"may refer to:\\n\\n*\") == False]\n",
    "data = data[data['text'].str.contains(\"can refer to:\\n\") == False]\n",
    "data = data[data['text'].str.contains(\"could refer to:\\n\") == False]\n",
    "data = data[data['text'].str.contains(\"#REDIRECT\") == False]\n",
    "data = data[data['text'].str.contains(\"== Matches ==\\n:\") == False]\n",
    "data = data[data['text'].str.contains(\"{{underconstruction\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:28:11.456232Z",
     "start_time": "2018-08-27T17:26:23.235156Z"
    }
   },
   "outputs": [],
   "source": [
    "data['cleaned_text'] = data['text'].apply(clean_wiki_markup)\n",
    "data['num_web_citations'] = data['text'].apply(find_num_web_citations)\n",
    "data['num_book_citations'] = data['text'].apply(find_num_book_citations)\n",
    "data['num_news_citations'] = data['text'].apply(find_num_news_citations)\n",
    "data['num_quotes'] = data['text'].apply(find_num_quotes)\n",
    "data['num_h3_headers'] = data['text'].apply(find_num_h3_headers)\n",
    "data['num_internal_links'] = data['text'].apply(find_num_internal_links)\n",
    "data['num_h2_headers'] = data['text'].apply(find_num_h2_headers)\n",
    "data['has_infobox'] = data['text'].str.contains('{{Infobox').astype(int)\n",
    "data['num_categories'] = data['text'].apply(find_num_categories)\n",
    "data['num_images'] = data['text'].apply(find_num_images)\n",
    "data['num_ISBN'] = data['text'].apply(find_num_ISBN)\n",
    "data['num_references'] = data['text'].apply(find_num_references)\n",
    "data['article_length'] = data['text'].apply(find_article_length)\n",
    "data['num_difficult_words'] = data['cleaned_text'].apply(find_num_difficult_words)\n",
    "data['dale_chall_readability_score'] = data['cleaned_text'].apply(find_dale_chall_readability_score)\n",
    "data['readability_index'] = data['cleaned_text'].apply(find_automated_readability_index)\n",
    "data['linsear_write_formula'] = data['cleaned_text'].apply(find_linsear_write_formula)\n",
    "data['gunning_fog_index'] = data['cleaned_text'].apply(find_gunning_fog_index)\n",
    "data['smog_index'] = data['cleaned_text'].apply(find_smog_index)\n",
    "data['syllable_count'] = data['cleaned_text'].apply(find_syllable_count)\n",
    "data['lexicon_count'] = data['cleaned_text'].apply(find_lexicon_count)\n",
    "data['sentence_count'] = data['cleaned_text'].apply(find_sentence_count)\n",
    "data['num_footnotes'] = data['text'].apply(find_num_footnotes)\n",
    "data['num_note_tags'] = data['text'].apply(find_num_note_tags)\n",
    "data['num_underlines'] = data['text'].apply(find_num_underlines)\n",
    "data['num_journal_citations'] = data['text'].apply(find_num_journal_citations)\n",
    "data['num_about_links'] = data['text'].apply(find_num_about_links)\n",
    "data['num_wikitables'] = data['text'].apply(find_num_wikitables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:32:14.054382Z",
     "start_time": "2018-08-27T17:32:13.719005Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Pickle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T21:53:50.789497Z",
     "start_time": "2018-08-25T21:53:50.684662Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_pickle('Machine_Learning_Category_Wikipedia.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Split data into corrext input (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:32:17.389984Z",
     "start_time": "2018-08-27T17:32:17.339859Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.loc[:, ['has_infobox','num_categories','num_images','num_ISBN','num_references','article_length',\n",
    "                'num_difficult_words','dale_chall_readability_score','readability_index','linsear_write_formula',\n",
    "                'gunning_fog_index', 'num_web_citations','num_book_citations','num_news_citations',\n",
    "                'num_quotes','num_h3_headers','num_internal_links', 'num_h2_headers', 'syllable_count',\n",
    "                'lexicon_count', 'sentence_count','num_footnotes', 'num_note_tags', 'num_underlines', 'num_journal_citations',\n",
    "                'num_about_links', 'num_wikitables', 'smog_index']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T21:56:43.119561Z",
     "start_time": "2018-08-25T21:56:42.780189Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_model = pickle.load(open('../src/random_forest_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:32:21.715429Z",
     "start_time": "2018-08-27T17:32:20.628872Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = rf_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:32:24.129341Z",
     "start_time": "2018-08-27T17:32:24.086606Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Predicted_Quality'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:32:25.187484Z",
     "start_time": "2018-08-27T17:32:25.142782Z"
    }
   },
   "outputs": [],
   "source": [
    "Cat_page_df = data.loc[:, ['category', 'page', 'Predicted_Quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:32:26.079495Z",
     "start_time": "2018-08-27T17:32:25.995701Z"
    }
   },
   "outputs": [],
   "source": [
    "Cat_page_df.groupby(by='category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T02:38:59.656856Z",
     "start_time": "2018-08-26T02:38:59.566346Z"
    }
   },
   "outputs": [],
   "source": [
    "data[data['Predicted_Quality'] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T02:39:56.011054Z",
     "start_time": "2018-08-26T02:39:55.888577Z"
    }
   },
   "outputs": [],
   "source": [
    "data[data['category'] == 'Artificial neural networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T12:06:57.920639Z",
     "start_time": "2018-08-26T12:06:57.519521Z"
    }
   },
   "outputs": [],
   "source": [
    "type(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T12:36:36.938369Z",
     "start_time": "2018-08-26T12:36:36.894202Z"
    }
   },
   "outputs": [],
   "source": [
    "ML_page_predictions = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T12:37:35.907580Z",
     "start_time": "2018-08-26T12:37:35.569721Z"
    }
   },
   "outputs": [],
   "source": [
    "ML_page_predictions.to_pickle('ML_page_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:48:58.457751Z",
     "start_time": "2018-08-28T17:48:58.414593Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wiki_category_quality(category):\n",
    "    category = category\n",
    "    browser = Chrome()\n",
    "    browse_to_category(browser, category)\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    category_db = client['category_db']\n",
    "    collection = dogs_db['category_db']\n",
    "    subs = get_sub_categories(browser)\n",
    "    for sub_cat in subs:\n",
    "        browse_to_category(browser, category)\n",
    "        time.sleep(2)\n",
    "        click_to_sub_category_page(browser, sub_cat)\n",
    "        title = get_category_title(browser)\n",
    "        try:\n",
    "            w = browser.find_element_by_class_name('mw-category')\n",
    "            pages = filter_pages(w.text.split('\\n'))\n",
    "            for page in pages:\n",
    "                post = {'category': title,\n",
    "                    'page': page,\n",
    "                    'text' : get_wiki_xml(page)}\n",
    "                posts = dogs_db.posts\n",
    "                post = posts.insert_one(post)\n",
    "        except NoSuchElementException:\n",
    "            w = browser.find_elements_by_class_name('mw-content-ltr')\n",
    "            pages = filter_pages(w[0].text.split('\\n'))[2:]\n",
    "            for page in pages:\n",
    "                post = {'category': title,\n",
    "                    'page': page,\n",
    "                    'text' : get_wiki_xml(page)}\n",
    "                posts = dogs_db.posts\n",
    "                post = posts.insert_one(post)\n",
    "    data = pd.DataFrame(list(posts.find()))\n",
    "    data.drop(columns='_id',inplace=True)\n",
    "    data = data[data['text'] != \"\"]\n",
    "    data = data[data['text'].str.contains(\"#redirect\") == False]\n",
    "    data = data[data['text'].str.contains(\"may refer to:\\n\\n*\") == False]\n",
    "    data = data[data['text'].str.contains(\"can refer to:\\n\") == False]\n",
    "    data = data[data['text'].str.contains(\"could refer to:\\n\") == False]\n",
    "    data = data[data['text'].str.contains(\"#REDIRECT\") == False]\n",
    "    data = data[data['text'].str.contains(\"== Matches ==\\n:\") == False]\n",
    "    data = data[data['text'].str.contains(\"{{underconstruction\") == False]\n",
    "    data['cleaned_text'] = data['text'].apply(clean_wiki_markup)\n",
    "    data['num_web_citations'] = data['text'].apply(find_num_web_citations)\n",
    "    data['num_book_citations'] = data['text'].apply(find_num_book_citations)\n",
    "    data['num_news_citations'] = data['text'].apply(find_num_news_citations)\n",
    "    data['num_quotes'] = data['text'].apply(find_num_quotes)\n",
    "    data['num_h3_headers'] = data['text'].apply(find_num_h3_headers)\n",
    "    data['num_internal_links'] = data['text'].apply(find_num_internal_links)\n",
    "    data['num_h2_headers'] = data['text'].apply(find_num_h2_headers)\n",
    "    data['has_infobox'] = data['text'].str.contains('{{Infobox').astype(int)\n",
    "    data['num_categories'] = data['text'].apply(find_num_categories)\n",
    "    data['num_images'] = data['text'].apply(find_num_images)\n",
    "    data['num_ISBN'] = data['text'].apply(find_num_ISBN)\n",
    "    data['num_references'] = data['text'].apply(find_num_references)\n",
    "    data['article_length'] = data['text'].apply(find_article_length)\n",
    "    data['num_difficult_words'] = data['cleaned_text'].apply(find_num_difficult_words)\n",
    "    data['dale_chall_readability_score'] = data['cleaned_text'].apply(find_dale_chall_readability_score)\n",
    "    data['readability_index'] = data['cleaned_text'].apply(find_automated_readability_index)\n",
    "    data['linsear_write_formula'] = data['cleaned_text'].apply(find_linsear_write_formula)\n",
    "    data['gunning_fog_index'] = data['cleaned_text'].apply(find_gunning_fog_index)\n",
    "    data['smog_index'] = data['cleaned_text'].apply(find_smog_index)\n",
    "    data['syllable_count'] = data['cleaned_text'].apply(find_syllable_count)\n",
    "    data['lexicon_count'] = data['cleaned_text'].apply(find_lexicon_count)\n",
    "    data['sentence_count'] = data['cleaned_text'].apply(find_sentence_count)\n",
    "    data['num_footnotes'] = data['text'].apply(find_num_footnotes)\n",
    "    data['num_note_tags'] = data['text'].apply(find_num_note_tags)\n",
    "    data['num_underlines'] = data['text'].apply(find_num_underlines)\n",
    "    data['num_journal_citations'] = data['text'].apply(find_num_journal_citations)\n",
    "    data['num_about_links'] = data['text'].apply(find_num_about_links)\n",
    "    data['num_wikitables'] = data['text'].apply(find_num_wikitables)\n",
    "    data.dropna(inplace=True)\n",
    "    X = data.loc[:, ['has_infobox','num_categories','num_images','num_ISBN','num_references','article_length',\n",
    "                'num_difficult_words','dale_chall_readability_score','readability_index','linsear_write_formula',\n",
    "                'gunning_fog_index', 'num_web_citations','num_book_citations','num_news_citations',\n",
    "                'num_quotes','num_h3_headers','num_internal_links', 'num_h2_headers', 'syllable_count',\n",
    "                'lexicon_count', 'sentence_count','num_footnotes', 'num_note_tags', 'num_underlines', 'num_journal_citations',\n",
    "                'num_about_links', 'num_wikitables', 'smog_index']].values\n",
    "    predictions = rf_model.predict(X)\n",
    "    data['Predicted_Quality'] = predictions\n",
    "    Cat_page_df = data.loc[:, ['category', 'page', 'Predicted_Quality']]\n",
    "    return Cat_page_df.groupby(by='category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T17:46:46.614056Z",
     "start_time": "2018-08-28T17:46:46.576105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-28T17:49:26.635Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "get_wiki_category_quality('machine_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:41:54.813226Z",
     "start_time": "2018-08-27T17:41:54.518319Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data = pickle.load( open( \"Machine_Learning_Category_Wikipedia.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T19:51:28.468334Z",
     "start_time": "2018-08-27T19:51:28.236908Z"
    }
   },
   "outputs": [],
   "source": [
    "X = ml_data.loc[:, ['has_infobox','num_categories','num_images','num_ISBN','num_references','article_length',\n",
    "                'num_difficult_words','dale_chall_readability_score','readability_index','linsear_write_formula',\n",
    "                'gunning_fog_index', 'num_web_citations','num_book_citations','num_news_citations',\n",
    "                'num_quotes','num_h3_headers','num_internal_links', 'num_h2_headers', 'syllable_count',\n",
    "                'lexicon_count', 'sentence_count','num_footnotes', 'num_note_tags', 'num_underlines', 'num_journal_citations',\n",
    "                'num_about_links', 'num_wikitables', 'smog_index']].values\n",
    "\n",
    "predictions = rf_model.predict(X)\n",
    "ml_data['Predicted_Quality'] = predictions\n",
    "ml_page_df = ml_data.loc[:, ['category', 'page', 'Predicted_Quality']]\n",
    "ml_page_df.groupby(by='category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T18:50:46.416399Z",
     "start_time": "2018-08-27T18:50:46.349105Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data.to_pickle('ML_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T20:14:59.988762Z",
     "start_time": "2018-08-27T20:14:59.935812Z"
    }
   },
   "outputs": [],
   "source": [
    "(ml_page_df[ml_page_df['category'] == 'Applied machine learning']).sort_values(by='Predicted_Quality', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T20:40:24.653482Z",
     "start_time": "2018-08-27T20:40:24.595063Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T20:40:30.394960Z",
     "start_time": "2018-08-27T20:40:30.344622Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_page_df.to_pickle('ML_pages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:44:41.720292Z",
     "start_time": "2018-08-27T21:44:41.514205Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data['category'] = ml_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:45:50.654761Z",
     "start_time": "2018-08-27T21:45:50.606890Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data.index = list(range(len(ml_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:46:24.291124Z",
     "start_time": "2018-08-27T21:46:24.242259Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_data.to_pickle('ML_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:47:55.262431Z",
     "start_time": "2018-08-27T21:47:55.213383Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, d in ml_data.iterrows():\n",
    "    print(d['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
