{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T19:03:26.337713Z",
     "start_time": "2018-08-25T19:03:24.528765Z"
    }
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "import urllib\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "from textstat.textstat import textstat\n",
    "from gensim.corpora import wikicorpus\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "# Make it pretty\n",
    "plt.style.use('ggplot')\n",
    "hash_vec_rf_model = pickle.load(open(\"../src/hash_vec2_aug23.pkl\", \"rb\" ))\n",
    "rf_model = pickle.load(open(\"../src/random_forest_aug22.pkl\", \"rb\" ))\n",
    "hash_vec_fitter = pickle.load(open(\"../src/hash_vec_fitter.pkl\", \"rb\" ))\n",
    "\n",
    "def get_wiki_xml(title):\n",
    "    title = title\n",
    "    params = { \"format\":\"xml\", \"action\":\"query\", \"prop\":\"revisions\", \"rvprop\":\"timestamp|user|comment|content\" }\n",
    "    params[\"titles\"] = \"API|%s\" % urllib.parse.quote(title.encode(\"utf8\"))\n",
    "    qs = \"&\".join(\"%s=%s\" % (k, v)  for k, v in params.items())\n",
    "    url = \"http://en.wikipedia.org/w/api.php?%s\" % qs\n",
    "    tree = lxml.etree.parse(urllib.request.urlopen(url))\n",
    "    revs = tree.xpath('//rev')\n",
    "    return (revs[-1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T20:23:18.023123Z",
     "start_time": "2018-08-23T20:23:17.950224Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_dataframe = pd.read_csv('../data/popular_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T20:23:18.369165Z",
     "start_time": "2018-08-23T20:23:18.322246Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_dataframe = popular_dataframe.loc[:, ['Category', 'Page']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T20:23:18.700046Z",
     "start_time": "2018-08-23T20:23:18.658092Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T20:23:19.354289Z",
     "start_time": "2018-08-23T20:23:19.297600Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "wiki_db = client['popular_wiki_database']\n",
    "\n",
    "collection = wiki_db['popular_wiki_database']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important note about collections (and databases) in MongoDB is that they are created lazily - none of the above commands have actually performed any operations on the MongoDB server. Collections and databases are created when the first document is inserted into them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T20:23:24.067703Z",
     "start_time": "2018-08-23T20:23:24.020935Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wiki_xml(title):\n",
    "    title = title\n",
    "    params = { \"format\":\"xml\", \"action\":\"query\", \"prop\":\"revisions\", \"rvprop\":\"timestamp|user|comment|content\" }\n",
    "    params[\"titles\"] = \"API|%s\" % urllib.parse.quote(title.encode(\"utf8\"))\n",
    "    qs = \"&\".join(\"%s=%s\" % (k, v)  for k, v in params.items())\n",
    "    url = \"http://en.wikipedia.org/w/api.php?%s\" % qs\n",
    "    tree = lxml.etree.parse(urllib.request.urlopen(url))\n",
    "    revs = tree.xpath('//rev')\n",
    "    return (revs[-1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T20:33:01.036658Z",
     "start_time": "2018-08-23T20:33:00.983239Z"
    }
   },
   "outputs": [],
   "source": [
    "pop = popular_dataframe.replace('\\xa0', ' ', regex=True)\n",
    "pop.drop_duplicates(subset='Page', inplace=True)\n",
    "pop.Page = pop.Page.astype(str, inplace=True)\n",
    "pop.dropna(inplace=True)\n",
    "pop['Page'] = pop['Page'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:15:15.794065Z",
     "start_time": "2018-08-23T23:12:12.451553Z"
    }
   },
   "outputs": [],
   "source": [
    "for category, title in zip(pop.Category, pop.Page):\n",
    "    wiki_xml = get_wiki_xml(title)\n",
    "    post = {'category': category,\n",
    "            'title': title,\n",
    "            'text': wiki_xml}\n",
    "    posts = wiki_db.posts\n",
    "    post_id = posts.insert_one(post).inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:16:38.425176Z",
     "start_time": "2018-08-23T23:16:27.741346Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(posts.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:24:44.300798Z",
     "start_time": "2018-08-23T23:20:24.768215Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_dataframe['Page'] = popular_dataframe['Page'].astype(str, inplace=True)\n",
    "popular_dataframe['text'] = popular_dataframe['Page'].apply(get_wiki_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:27:33.698469Z",
     "start_time": "2018-08-23T23:27:33.183773Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_dataframe = popular_dataframe[popular_dataframe['text'] != \"\"]\n",
    "popular_dataframe = popular_dataframe[popular_dataframe['text'].str.contains(\"#redirect\") == False]\n",
    "popular_dataframe = popular_dataframe[popular_dataframe['text'].str.contains(\"may refer to:\\n\\n*\") == False]\n",
    "popular_dataframe = popular_dataframe[popular_dataframe['text'].str.contains(\"can refer to:\\n\") == False]\n",
    "popular_dataframe = popular_dataframe[popular_dataframe['text'].str.contains(\"could refer to:\\n\") == False]\n",
    "popular_dataframe = popular_dataframe[popular_dataframe['text'].str.contains(\"#REDIRECT\") == False]\n",
    "popular_dataframe = popular_dataframe[popular_dataframe['text'].str.contains(\"== Matches ==\\n:\") == False]\n",
    "popular_dataframe = popular_dataframe[popular_dataframe['text'].str.contains(\"{{underconstruction\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T15:21:29.948868Z",
     "start_time": "2018-08-23T15:21:29.889067Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_engineered_features(raw_text):\n",
    "    cleaned_text = clean_wiki_markup(raw_text)\n",
    "    return {\n",
    "        'cleaned_text': cleaned_text,\n",
    "        'num_web_citations': find_num_web_citations(raw_text),\n",
    "        'num_book_citations': find_num_book_citations(raw_text),\n",
    "        'num_news_citations': find_num_news_citations(raw_text),\n",
    "        'num_quotes': find_num_quotes(raw_text),\n",
    "        'num_h3_headers': find_num_h3_headers(raw_text),\n",
    "        'num_internal_links': find_num_internal_links(raw_text),\n",
    "        'num_h2_headers': find_num_h2_headers(raw_text),\n",
    "        'has_infobox': find_infobox(raw_text),\n",
    "        'num_categories': find_num_categories(raw_text),\n",
    "        'num_images': find_num_images(raw_text),\n",
    "        'num_ISBN': find_num_ISBN(raw_text),\n",
    "        'num_references': find_num_references(raw_text),\n",
    "        'article_length': find_article_length(raw_text),\n",
    "        'num_difficult_words': find_num_difficult_words(cleaned_text),\n",
    "        'dale_chall_readability_score': find_dale_chall_readability_score(cleaned_text),\n",
    "        'readability_index': find_automated_readability_index(cleaned_text),\n",
    "        'linsear_write_formula': find_linsear_write_formula(cleaned_text),\n",
    "        'gunning_fog_index': find_gunning_fog_index(cleaned_text),\n",
    "        'smog_index': find_smog_index(cleaned_text),\n",
    "        'syllable_count': find_syllable_count(cleaned_text),\n",
    "        'lexicon_count': find_lexicon_count(cleaned_text),\n",
    "        'sentence_count': find_sentence_count(cleaned_text),\n",
    "        'num_footnotes': find_num_footnotes(raw_text),\n",
    "        'num_note_tags': find_num_note_tags(raw_text),\n",
    "        'num_underlines': find_num_underlines(raw_text),\n",
    "        'num_journal_citations': find_num_journal_citations(raw_text),\n",
    "        'num_about_links': find_num_about_links(raw_text),\n",
    "        'num_wikitables': find_num_wikitables(raw_text)}\n",
    "\n",
    "def get_engineered_dataframe_no_label(raw_dataframe):\n",
    "    engineered_df = pd.DataFrame(raw_dataframe['text'].apply(create_engineered_features).tolist())\n",
    "    return engineered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:34:29.135729Z",
     "start_time": "2018-08-23T23:28:35.400526Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_dataframe['cleaned_text'] = popular_dataframe['text'].apply(clean_wiki_markup)\n",
    "popular_dataframe['num_web_citations'] = popular_dataframe['text'].apply(find_num_web_citations)\n",
    "popular_dataframe['num_book_citations'] = popular_dataframe['text'].apply(find_num_book_citations)\n",
    "popular_dataframe['num_news_citations'] = popular_dataframe['text'].apply(find_num_news_citations)\n",
    "popular_dataframe['num_quotes'] = popular_dataframe['text'].apply(find_num_quotes)\n",
    "popular_dataframe['num_h3_headers'] = popular_dataframe['text'].apply(find_num_h3_headers)\n",
    "popular_dataframe['num_internal_links'] = popular_dataframe['text'].apply(find_num_internal_links)\n",
    "popular_dataframe['num_h2_headers'] = popular_dataframe['text'].apply(find_num_h2_headers)\n",
    "popular_dataframe['has_infobox'] = popular_dataframe['text'].str.contains('{{Infobox').astype(int)\n",
    "popular_dataframe['num_categories'] = popular_dataframe['text'].apply(find_num_categories)\n",
    "popular_dataframe['num_images'] = popular_dataframe['text'].apply(find_num_images)\n",
    "popular_dataframe['num_ISBN'] = popular_dataframe['text'].apply(find_num_ISBN)\n",
    "popular_dataframe['num_references'] = popular_dataframe['text'].apply(find_num_references)\n",
    "popular_dataframe['article_length'] = popular_dataframe['text'].apply(find_article_length)\n",
    "popular_dataframe['num_difficult_words'] = popular_dataframe['cleaned_text'].apply(find_num_difficult_words)\n",
    "popular_dataframe['dale_chall_readability_score'] = popular_dataframe['cleaned_text'].apply(find_dale_chall_readability_score)\n",
    "popular_dataframe['readability_index'] = popular_dataframe['cleaned_text'].apply(find_automated_readability_index)\n",
    "popular_dataframe['linsear_write_formula'] = popular_dataframe['cleaned_text'].apply(find_linsear_write_formula)\n",
    "popular_dataframe['gunning_fog_index'] = popular_dataframe['cleaned_text'].apply(find_gunning_fog_index)\n",
    "popular_dataframe['smog_index'] = popular_dataframe['cleaned_text'].apply(find_smog_index)\n",
    "popular_dataframe['syllable_count'] = popular_dataframe['cleaned_text'].apply(find_syllable_count)\n",
    "popular_dataframe['lexicon_count'] = popular_dataframe['cleaned_text'].apply(find_lexicon_count)\n",
    "popular_dataframe['sentence_count'] = popular_dataframe['cleaned_text'].apply(find_sentence_count)\n",
    "popular_dataframe['num_footnotes'] = popular_dataframe['text'].apply(find_num_footnotes)\n",
    "popular_dataframe['num_note_tags'] = popular_dataframe['text'].apply(find_num_note_tags)\n",
    "popular_dataframe['num_underlines'] = popular_dataframe['text'].apply(find_num_underlines)\n",
    "popular_dataframe['num_journal_citations'] = popular_dataframe['text'].apply(find_num_journal_citations)\n",
    "popular_dataframe['num_about_links'] = popular_dataframe['text'].apply(find_num_about_links)\n",
    "popular_dataframe['num_wikitables'] = popular_dataframe['text'].apply(find_num_wikitables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T23:38:54.387557Z",
     "start_time": "2018-08-22T23:38:54.264981Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_wiki_markup(raw_article):\n",
    "    semi_cleaned_article = wikicorpus.filter_wiki(raw_article)\n",
    "    cleaned_article = semi_cleaned_article.replace(\"\\n\", \"\").replace(\"\\'\", \"\").replace(\"()\", \"\").replace(\"=\", \"\").replace(\"|alt\",\"\").replace(\"\\xa0\",\"\")\n",
    "    return cleaned_article\n",
    "def find_num_categories(raw_article):\n",
    "    return raw_article.count(\"[[Category:\")\n",
    "def find_num_images(raw_article):\n",
    "    return raw_article.count(\"[[Image:\")\n",
    "def find_num_ISBN(raw_article):\n",
    "    return raw_article.count(\"ISBN\")\n",
    "def find_num_references(raw_article):\n",
    "    return raw_article.count(\"</ref>\")\n",
    "def find_article_length(cleaned_article):\n",
    "    return len(cleaned_article)\n",
    "def find_num_difficult_words(cleaned_article):\n",
    "    return textstat.difficult_words(cleaned_article)\n",
    "def find_dale_chall_readability_score(cleaned_article):\n",
    "    return textstat.dale_chall_readability_score(cleaned_article)\n",
    "def find_automated_readability_index(cleaned_article):\n",
    "    return textstat.automated_readability_index(cleaned_article)\n",
    "def find_linsear_write_formula(cleaned_article):\n",
    "    return textstat.linsear_write_formula(cleaned_article)\n",
    "def find_gunning_fog_index(cleaned_article):\n",
    "    return textstat.gunning_fog(cleaned_article)\n",
    "def find_syllable_count(cleaned_article):\n",
    "    return textstat.syllable_count(cleaned_article)\n",
    "def find_lexicon_count(cleaned_article):\n",
    "    return textstat.lexicon_count(cleaned_article, removepunct=True)\n",
    "def find_sentence_count(cleaned_article):\n",
    "    return textstat.sentence_count(cleaned_article)\n",
    "def find_smog_index(cleaned_article):\n",
    "    return textstat.smog_index(cleaned_article)\n",
    "def find_num_web_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite web\")\n",
    "def find_num_book_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite book\")\n",
    "def find_num_news_citations(raw_article):\n",
    "    return raw_article.count(\"{{cite news\")\n",
    "def find_num_quotes(raw_article):\n",
    "    return raw_article.count(\"quote=\")\n",
    "def find_num_h3_headers(raw_article):\n",
    "    return raw_article.count(\"\\n===\")\n",
    "def find_num_internal_links(raw_article):\n",
    "    return (raw_article.count(\"[[\") // 2)\n",
    "def find_num_h2_headers(raw_article):\n",
    "    return (raw_article.count(\"\\n==\") - find_num_h3_headers(raw_article))\n",
    "def find_num_note_tags(raw_article):\n",
    "    return raw_article.count(\"{{note\")\n",
    "def find_num_bullet_points(raw_article):\n",
    "    return (raw_article.count(\"*\"))\n",
    "def find_num_underlines(raw_article):\n",
    "    return (raw_article.count(\"<u>\"))\n",
    "def find_num_journal_citations(raw_article):\n",
    "    return (raw_article.count(\"{{cite journal\"))\n",
    "def find_num_about_links(raw_article):\n",
    "    return (raw_article.count(\"{{About\"))\n",
    "def find_num_wikitables(raw_article):\n",
    "    return (raw_article.count('class=\"wikitable'))\n",
    "def find_num_footnotes(raw_article):\n",
    "    return raw_article.count(\"{{\")\n",
    "def find_infobox(raw_article):\n",
    "    return int('{{Infobox' in raw_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T18:58:27.793328Z",
     "start_time": "2018-08-23T18:58:27.659423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2970, 32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_dataframe.dropna(inplace=True)\n",
    "popular_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make backup dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T17:51:42.859014Z",
     "start_time": "2018-08-23T17:51:42.728011Z"
    }
   },
   "outputs": [],
   "source": [
    "backup_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform data for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:37:56.592807Z",
     "start_time": "2018-08-23T23:37:56.548498Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_X = popular_dataframe.loc[:, ['has_infobox','num_categories','num_images','num_ISBN','num_references','article_length',\n",
    "                'num_difficult_words','dale_chall_readability_score','readability_index','linsear_write_formula',\n",
    "                'gunning_fog_index', 'num_web_citations','num_book_citations','num_news_citations',\n",
    "                'num_quotes','num_h3_headers','num_internal_links', 'num_h2_headers', 'syllable_count',\n",
    "                'lexicon_count', 'sentence_count','num_footnotes', 'num_note_tags', 'num_underlines', 'num_journal_citations',\n",
    "                'num_about_links', 'num_wikitables', 'smog_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:38:08.516007Z",
     "start_time": "2018-08-23T23:38:07.753422Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_preds = rf_model.predict(rf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:38:52.790086Z",
     "start_time": "2018-08-23T23:38:52.743501Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_dataframe['random_forest_preds'] = rf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T23:39:53.996467Z",
     "start_time": "2018-08-23T23:39:53.947257Z"
    }
   },
   "outputs": [],
   "source": [
    "category_df = popular_dataframe.loc[:, ['Category','random_forest_preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T19:03:35.672819Z",
     "start_time": "2018-08-25T19:03:35.625922Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wiki_xml(title):\n",
    "    title = title\n",
    "    params = { \"format\":\"xml\", \"action\":\"query\", \"prop\":\"revisions\", \"rvprop\":\"timestamp|user|comment|content\" }\n",
    "    params[\"titles\"] = \"API|%s\" % urllib.parse.quote(title.encode(\"utf8\"))\n",
    "    qs = \"&\".join(\"%s=%s\" % (k, v)  for k, v in params.items())\n",
    "    url = \"http://en.wikipedia.org/w/api.php?%s\" % qs\n",
    "    tree = lxml.etree.parse(urllib.request.urlopen(url))\n",
    "    revs = tree.xpath('//rev')\n",
    "    return (revs[-1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T20:15:09.287682Z",
     "start_time": "2018-08-25T20:15:08.589347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following table compares some of the most popular [[software framework]]s, [[software library|libraries]] and [[computer program]]s for [[deep learning]].\\n\\n<!-- This is a list of software with a corresponding Wikipedia article -->\\n\\n==Deep learning software by name==\\n{| class=\"wikitable sortable\" style=\"text-align: center; font-size: 85%; width: auto; table-layout: fixed;\"\\n|-\\n! style=\"width: 12em\" | Software\\n! Creator\\n! Software license{{efn|name=\"license\"|Licenses here are a summary, and are not taken to be complete statements of the licenses. Some libraries may use other libraries internally under different licenses}}\\n! Open source\\n! Platform\\n! Written in\\n! Interface\\n! [[OpenMP]] support\\n! [[OpenCL]] support\\n! [[CUDA]] support\\n!Parallel execution (multi node)\\n! [[Automatic differentiation]]<ref>{{cite arXiv |author1=Atilim Gunes Baydin |author2=Barak A. Pearlmutter |author3=Alexey Andreyevich Radul |author4=Jeffrey Mark Siskind |eprint=1502.05767 |title=Automatic differentiation in machine learning: a survey |class=cs.LG |date=20 February 2015}}</ref>\\n! Has pretrained models\\n! [[Recurrent neural network|Recurrent net]]s\\n! [[Convolutional neural network|Convolutional nets]]\\n! [[Restricted Boltzmann machine|RBM]]/[[deep belief network|DBNs]]\\n![[Metal (API)|Metal]] support\\n|-\\n|[https://roNNie.ai roNNie.ai]\\n|Kevin Lok\\n|[[MIT]]\\n|{{Yes}}\\n|Linux, macOS, Windows\\n|Python\\n|Python\\n|\\n|\\n|{{Yes}}\\n|\\n|\\n|{{Yes}}\\n|{{Yes}}\\n|{{Yes}}\\n|\\n|\\n|-\\n|[[BigDL]]\\n|Jason Dai\\n|[[Apache License|Apache 2.0]]\\n|Yes\\n|Apache Spark\\n|Scala\\n|Scala, Python\\n|\\n|\\n| {{No}}\\n|\\n|\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|\\n|-\\n| [[Caffe (software)|Caffe]]\\n| Berkeley Vision and Learning Center\\n| {{Free|[[BSD licenses|BSD license]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]<ref>{{cite web|url=https://github.com/Microsoft/caffe|title=Microsoft/caffe|work=GitHub}}</ref>\\n| [[C++]]\\n| [[Python (programming language)|Python]], [[MATLAB]], [[C++]]\\n| {{Yes}}\\n| {{Depends|Under development<ref>{{cite web|url=https://github.com/BVLC/caffe/tree/opencl|title=OpenCL Caffe}}</ref>}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=http://caffe.berkeleyvision.org/model_zoo.html|title=Caffe Model Zoo}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Dunno}}\\n|\\n|-\\n| [[Deeplearning4j]] \\n| Skymind engineering team; Deeplearning4j community; originally [[Adam Gibson (computer scientist)|Adam Gibson]]\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]], [[Android (operating system)|Android]] ([[Cross-platform]])\\n| [[C++]], [[Java (programming language)|Java]]\\n| [[Java (programming language)|Java]], [[Scala (programming language)|Scala]], [[Clojure (programming language)|Clojure]], [[Python (programming language)|Python]] ([[Keras]]), [[Kotlin (programming language)|Kotlin]]\\n| {{Yes}}\\n| {{Depends|On roadmap}}<ref>{{cite web|url=https://github.com/deeplearning4j/nd4j/issues/27|title=Support for Open CL · Issue #27 · deeplearning4j/nd4j|work=GitHub}}</ref>\\n| {{Yes}}<ref>{{cite web|url=http://nd4j.org/gpu_native_backends.html|title=N-Dimensional Scientific Computing for Java|publisher=}}</ref><ref>{{cite web|url=https://deeplearning4j.org/compare-dl4j-tensorflow-pytorch|title=Comparing Top Deep Learning Frameworks|publisher=Deeplearning4j}}</ref>\\n| {{Yes|Computational Graph}}\\n| {{Yes}}<ref>{{cite web|url=http://deeplearning4j.org/model-zoo|title=Deeplearning4j Models|author1=Chris Nicholson|author2= Adam Gibson|publisher=}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=http://deeplearning4j.org/spark|title=Deeplearning4j on Spark|author=Deeplearning4j|publisher=Deeplearning4j}}</ref>\\n|\\n|-\\n|[[Chainer]]\\n|Preferred Networks\\n| {{Free|[[MIT license]]}}\\n| {{Yes}}\\n|[[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\\n|\\n|Python\\n| {{No}}\\n| {{No}}<ref>https://github.com/chainer/chainer/pull/2717</ref><ref>https://github.com/chainer/chainer/issues/99</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|\\n|\\n|-\\n|Darknet\\n|Joseph Redmon\\n| {{Free|[[Public Domain]]}}\\n| {{Yes}}\\n| [[Cross-platform|Cross-Platform]]\\n| [[C (programming language)|C]]\\n| [[C (programming language)|C]], [[Python (programming language)|Python]]\\n| {{Yes}}\\n| {{No}}<ref>https://github.com/pjreddie/darknet/issues/127</ref>\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|\\n|\\n|\\n|\\n|\\n|-\\n|[[Dlib]]\\n|Davis King\\n| {{Free|[[Boost Software License]]}}\\n| {{Yes}}\\n|[[Cross-platform|Cross-Platform]]\\n|[[C++]]\\n|[[C++]]\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|-\\n|[[DataMelt]] (DMelt)\\n| S.Chekanov\\n| {{Free|[[Freemium]]}}\\n| {{Yes}}\\n|[[Cross-platform|Cross-Platform]]\\n| [[Java (programming language)|Java]]\\n| [[Java (programming language)|Java]]\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n|\\n|-\\n|DyNet\\n|Carnegie Mellon University\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n|[[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\\n|\\n|[[C++]], [[Python (programming language)|Python]]\\n|\\n| {{No}}<ref>https://github.com/clab/dynet/issues/405</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|\\n|\\n|\\n|\\n|-\\n| Intel [[Data Analytics Acceleration Library]]\\n| Intel\\n| {{Free|[[Apache License 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]] on [[Intel]] [[Central processing unit|CPU]]<ref name=\"intel-daal\">[https://software.intel.com/intel-daal Intel® Data Analytics Acceleration Library (Intel® DAAL) | Intel® Software]</ref>\\n| [[C++]], [[Python (programming language)|Python]], [[Java (programming language)|Java]]\\n| [[C++]], [[Python (programming language)|Python]], [[Java (programming language)|Java]]<ref name=\"intel-daal\"/>\\n| {{Yes}}\\n| {{No}}\\n| {{No}}\\n| {{Yes}}\\n| {{No}}\\n| \\n| {{Yes}}\\n| \\n| {{Yes}}\\n|\\n|-\\n| Intel [[Math Kernel Library]]\\n| Intel\\n| {{Proprietary}}\\n| {{No}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]] on [[Intel]] [[Central processing unit|CPU]]<ref>[https://software.intel.com/mkl Intel® Math Kernel Library (Intel® MKL) | Intel® Software]</ref>\\n| \\n| [[C (programming language)|C]]<ref>[https://software.intel.com/en-us/mkl-developer-reference-c-deep-neural-network-functions Deep Neural Network Functions]</ref>\\n| {{Yes}}<ref>[https://software.intel.com/en-us/articles/intel-math-kernel-library-intel-mkl-using-intel-mkl-with-threaded-applications Using Intel® MKL with Threaded Applications | Intel® Software]</ref>\\n| {{No}}\\n| {{No}}\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}<ref name=\"intel-benchmark\">[https://software.intel.com/en-us/articles/intel-xeon-phi-delivers-competitive-performance-for-deep-learning-and-getting-better-fast Intel® Xeon Phi™ Delivers Competitive Performance For Deep Learning—And Getting Better Fast | Intel® Software]</ref>\\n| {{Yes}}<ref name=\"intel-benchmark\"/>\\n| \\n| {{No}}\\n|\\n|-\\n| [[Keras]]\\n| François Chollet\\n| {{Free|[[MIT license]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\\n| [[Python (programming language)|Python]]\\n| [[Python (programming language)|Python]], [[R (programming language)|R]]\\n| {{Depends|Only if using Theano as backend}}\\n| {{Depends|Under development for the Theano backend (and on roadmap for the TensorFlow backend)}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>https://keras.io/applications/</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>[https://github.com/fchollet/keras/issues/2436 Does Keras support using multiple GPUs? · Issue #2436 · fchollet/keras]</ref>\\n|\\n|-\\n| [[MATLAB]] + Neural Network Toolbox \\n| [[MathWorks]] \\n| {{Proprietary}} \\n| {{No}} \\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]] \\n| [[C (programming language)|C]], [[C++]], [[Java (programming language)|Java]], [[MATLAB]] \\n| [[MATLAB]] \\n| {{No}} \\n| {{No}} \\n| {{Yes|Train with Parallel Computing Toolbox and generate CUDA code with GPU Coder}}<ref>{{cite web|title=GPU Coder - MATLAB & Simulink|url=https://www.mathworks.com/products/gpu-coder.html|website=MathWorks|accessdate=13 November 2017}}</ref> \\n| {{No}} \\n| {{Yes}}<ref name=\"NNT\">{{cite web|title=Neural Network Toolbox - MATLAB|url=https://www.mathworks.com/products/neural-network.html|website=MathWorks|accessdate=13 November 2017}}</ref><ref>{{cite web|title=Deep Learning Models - MATLAB & Simulink|url=https://www.mathworks.com/solutions/deep-learning/models.html|website=MathWorks|accessdate=13 November 2017}}</ref> \\n| {{Yes}}<ref name=\"NNT\"/> \\n| {{Yes}}<ref name=\"NNT\"/> \\n| {{Yes}}<ref name=\"NNT\"/>\\n| {{Yes|With Parallel Computing Toolbox}}<ref>{{cite web|title=Parallel Computing Toolbox - MATLAB|url=https://www.mathworks.com/products/parallel-computing.html|website=MathWorks|accessdate=13 November 2017}}</ref>\\n|\\n|-\\n| [[Microsoft Cognitive Toolkit]] \\n| [[Microsoft Research]]\\n| {{Free|[[MIT license]]}}<ref>{{cite web|url=https://github.com/Microsoft/CNTK/blob/master/LICENSE.md|title=CNTK/LICENSE.md at master · Microsoft/CNTK · GitHub|work=GitHub}}</ref>\\n| {{Yes}}\\n| [[Microsoft Windows|Windows]], [[Linux]]<ref name=\"Setup CNTK on your machine\">{{cite web|url=https://github.com/Microsoft/CNTK/wiki/Setup-CNTK-on-your-machine|title=Setup CNTK on your machine|work=GitHub}}</ref> ([[macOS]] via Docker on roadmap)\\n| [[C++]]\\n| [[Python (programming language)|Python (]][[Keras]]), [[C++]],  [[Command line]],<ref>{{cite web|url=https://github.com/Microsoft/CNTK/wiki/CNTK-usage-overview|title=CNTK usage overview|work=GitHub}}</ref> BrainScript<ref>{{cite web|url=https://github.com/Microsoft/CNTK/wiki/BrainScript-Network-Builder|title=BrainScript Network Builder|work=GitHub}}</ref> ([[.NET Framework|.NET]] on roadmap<ref>{{cite web|url=https://github.com/Microsoft/CNTK/issues/960|title=.NET Support · Issue #960 · Microsoft/CNTK|work=GitHub}}</ref>)\\n| {{Yes}}<ref>{{cite web|url=https://github.com/Microsoft/CNTK/issues/59#issuecomment-178104505|title=How to train a model using multiple machines? · Issue #59 · Microsoft/CNTK|work=GitHub}}</ref>\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>https://github.com/Microsoft/CNTK/issues/140#issuecomment-186466820</ref>\\n| {{Yes}}<ref name=\"cntk.ai\">{{cite web|url=http://www.cntk.ai/|title=CNTK - Computational Network Toolkit|publisher=Microsoft Corporation}}</ref>\\n| {{Yes}}<ref name=\"cntk.ai\" />\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=https://github.com/Microsoft/CNTK/wiki/Multiple-GPUs-and-machines|title=Multiple GPUs and machines|publisher=Microsoft Corporation}}</ref>\\n|\\n|-\\n| Apache [[MXNet]]\\n| Apache Software Foundation\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]],<ref>{{cite web|url=https://github.com/dmlc/mxnet/releases|title=Releases · dmlc/mxnet|work=Github}}</ref><ref>{{cite web|url=https://mxnet.readthedocs.io/en/latest/how_to/build.html#building-on-windows|title=Installation Guide — mxnet documentation|work=Readthdocs}}</ref> [[Amazon Web Services|AWS]], [[Android (operating system)|Android]],<ref>{{cite web|url=https://mxnet.readthedocs.io/en/latest/how_to/smart_device.html|title=MXNet Smart Device|work=ReadTheDocs}}</ref> [[iOS]], [[File manager|JavaScript]]<ref>{{cite web|url=https://github.com/dmlc/mxnet.js|title=MXNet.js|work=Github}}</ref>\\n| Small [[C++]] core library\\n| [[C++]], [[Python (programming language)|Python]], [[Julia (programming language)|Julia]], [[Matlab]], [[JavaScript]], [[Go (programming language)|Go]], [[R (programming language)|R]], [[Scala (programming language)|Scala]], [[Perl (programming language)|Perl]]\\n| {{Yes}}\\n| {{Depends|On roadmap}}<ref>{{cite web|url=https://github.com/dmlc/mxnet/issues/621|title=Support for other Device Types, OpenCL AMD GPU · Issue #621 · dmlc/mxnet|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Yes}}<ref>https://mxnet.readthedocs.io/</ref>\\n| {{Yes}}<ref>{{cite web|url=https://github.com/dmlc/mxnet-model-gallery|title=Model Gallery|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=https://mxnet.readthedocs.io/en/latest/how_to/multi_devices.html|title=Run MXNet on Multiple CPU/GPUs with Data Parallel|work=GitHub}}</ref>\\n|\\n|-\\n| [[Neural Designer]]\\n| Artelnics\\n| {{Proprietary}}\\n| {{No}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\\n| [[C++]]\\n| [[Graphical user interface]]\\n| {{Yes}}\\n| {{No}}\\n| {{No}}\\n| {{Dunno}}\\n| {{Dunno}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{Dunno}}\\n|\\n|-\\n| [[OpenNN]]\\n| Artelnics\\n| {{Free|[[GNU Lesser General Public License|GNU LGPL]]}}\\n| {{Yes}}\\n| [[Cross-platform]]\\n| [[C++]]\\n| [[C++]]\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}\\n| {{Dunno}}\\n| {{Dunno}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{Dunno}}\\n|\\n|-\\n|[https://github.com/plaidml/plaidml PlaidML]\\n|[http://vertex.ai Vertex.AI]\\n|[[AGPL 3|AGPL3]]\\n| {{Yes}}\\n|[[Linux]], [[macOS]], [[Windows]]\\n|[[C++]], [[Python (programming language)|Python]]\\n|Keras, Python, C++, C\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n| {{Yes}}\\n| {{Yes}}\\n| {{Dunno}}\\n| {{Yes}}\\n|-\\n| [[PyTorch]]\\n| Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan\\n| {{Free|[[BSD licenses|BSD license]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Windows]]\\n| [[Python (programming language)|Python]], [[C (programming language)|C]], [[CUDA]]\\n| [[Python (programming language)|Python]]\\n| {{Yes}}\\n| {{Depends|Via separately maintained package}}<ref>https://github.com/hughperkins/pytorch-coriander</ref><ref>https://github.com/pytorch/pytorch/issues/488</ref><ref>https://github.com/pytorch/pytorch/issues/488#issuecomment-273626736</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|-\\n| [[Apache SINGA]]\\n| [[Apache Incubator]]\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\\n| [[C++]]\\n| [[Python (programming language)|Python]], [[C++]], [[Java (programming language)|Java]]\\n| {{No}}\\n| {{Yes | In V1.0}}\\n| {{Yes}}\\n| {{Dunno}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|-\\n| [[TensorFlow]]\\n| [[Google Brain]] team\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]],<ref>https://developers.googleblog.com/2016/11/tensorflow-0-12-adds-support-for-windows.html</ref> [[Android (operating system)|Android]]\\n| [[C++]], [[Python (programming language)|Python]], [[CUDA]]\\n| [[Python (programming language)|Python]] ([[Keras]]), [[C (programming language)|C]]/[[C++]], [[Java (programming language)|Java]], [[Go (programming language)|Go]], [[R (programming language)|R]]<ref>{{Citation|last=interface)|first=JJ Allaire (R|title=tensorflow: R Interface to TensorFlow|date=2017-05-26|url=https://cran.r-project.org/web/packages/tensorflow/index.html|last2=RStudio|last3=Eddelbuettel|last4=Golding|last5=Tang|last6=Tutorials)|first3=Dirk|first4=Nick|first5=Yuan|first6=Google Inc (Examples and|accessdate=2017-06-14}}</ref>, [[Julia (programming language)|Julia]]\\n| {{No}}\\n| {{Depends|On roadmap}}<ref name=\"tensorflow-roadmap\">{{cite web|url=https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/about/roadmap.md|title=tensorflow/roadmap.md at master · tensorflow/tensorflow · GitHub | work=GitHub | date=January 23, 2017 | access-date=May 21, 2017}}</ref> but already with [[SYCL]]<ref name=\"GitHub\">{{cite web|url=https://github.com/tensorflow/tensorflow/issues/22|title=OpenCL support · Issue #22 · tensorflow/tensorflow|work=GitHub}}</ref> support\\n| {{Yes}}\\n| {{Yes}}<ref>https://www.tensorflow.org/</ref>\\n| {{Yes}}<ref>https://github.com/tensorflow/models</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|-\\n| [[TensorLayer]]\\n| Hao Dong\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]],<ref>https://developers.googleblog.com/2016/11/tensorflow-0-12-adds-support-for-windows.html</ref> [[Android (operating system)|Android]]\\n| [[C++]], [[Python (programming language)|Python]],\\n| [[Python (programming language)|Python]] \\n| {{No}}\\n| {{Depends|On roadmap}}<ref name=\"tensorflow-roadmap\">{{cite web|url=https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/about/roadmap.md|title=tensorflow/roadmap.md at master · tensorflow/tensorflow · GitHub | work=GitHub | date=January 23, 2017 | access-date=May 21, 2017}}</ref> but already with [[SYCL]]<ref name=\"GitHub\">{{cite web|url=https://github.com/tensorflow/tensorflow/issues/22|title=OpenCL support · Issue #22 · tensorflow/tensorflow|work=GitHub}}</ref> support\\n| {{Yes}}\\n| {{Yes}}<ref>https://www.tensorflow.org/</ref>\\n| {{Yes}}<ref>https://github.com/tensorflow/models</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|-\\n| [[Theano (software)|Theano]]\\n| [[Université de Montréal]]\\n| {{Free|[[BSD licenses|BSD license]]}}\\n| {{Yes}}\\n| [[Cross-platform]]\\n| [[Python (programming language)|Python]]\\n| [[Python (programming language)|Python]] ([[Keras]])\\n| {{Yes}}\\n| {{Depends|Under development<ref>{{cite web|url=http://deeplearning.net/software/theano/tutorial/using_gpu.html|title=Using the GPU — Theano 0.8.2 documentation|publisher=}}</ref>}}\\n| {{Yes}}\\n| {{Yes}}<ref>http://deeplearning.net/software/theano/library/gradient.html</ref><ref>https://groups.google.com/d/msg/theano-users/mln5g2IuBSU/gespG36Lf_QJ</ref>\\n| {{Depends|Through Lasagne\\'s model zoo<ref>{{cite web|url=https://github.com/Lasagne/Recipes/tree/master/modelzoo|title=Recipes/modelzoo at master · Lasagne/Recipes · GitHub|work=GitHub}}</ref>}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>[http://deeplearning.net/software/theano/tutorial/using_multi_gpu.html Using multiple GPUs — Theano 0.8.2 documentation]</ref>\\n|\\n|-\\n| [[Torch (machine learning)|Torch]]\\n| Ronan Collobert, Koray Kavukcuoglu, Clement Farabet\\n| {{Free|[[BSD licenses|BSD license]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]],<ref>https://github.com/torch/torch7/wiki/Windows</ref> [[Android (operating system)|Android]],<ref>{{cite web|url=https://github.com/soumith/torch-android|title=GitHub - soumith/torch-android: Torch-7 for Android|work=GitHub}}</ref> [[iOS]]\\n| [[C (programming language)|C]], [[Lua (programming language)|Lua]]\\n| [[Lua (programming language)|Lua]], [[Lua (programming language)|LuaJIT]],<ref>{{cite web|url=http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf|title=Torch7: A Matlab-like Environment for Machine Learning}}</ref> [[C (programming language)|C]], utility library for [[C++]]/[[OpenCL]]<ref name=jtorch>{{cite web|url=https://github.com/jonathantompson/jtorch|title=GitHub - jonathantompson/jtorch: An OpenCL Torch Utility Library|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Depends|Third party implementations<ref>{{cite web|url=https://github.com/torch/torch7/wiki/Cheatsheet#opencl|title=Cheatsheet|work=GitHub}}</ref><ref>{{cite web|url=https://github.com/hughperkins/distro-cl|title=cltorch|work=GitHub}}</ref>}}\\n| {{Yes}}<ref>{{cite web|url=https://github.com/torch/cutorch|title=Torch CUDA backend|work=GitHub}}</ref><ref>{{cite web|url=https://github.com/torch/cunn|title=Torch CUDA backend for nn|work=GitHub}}</ref>\\n| {{Yes|Through [[Twitter]]\\'s Autograd<ref>https://github.com/twitter/torch-autograd</ref>}}\\n| {{Yes}}<ref>{{cite web|url=https://github.com/torch/torch7/wiki/ModelZoo|title=ModelZoo|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>https://github.com/torch/torch7/wiki/Cheatsheet#distributed-computing--parallel-processing</ref>\\n|\\n|-\\n| [[Wolfram Mathematica]]\\n| [[Wolfram Research]]\\n| {{Proprietary}}\\n| {{No}}\\n| [[Microsoft Windows|Windows]], [[macOS]], [[Linux]], [[Cloud computing]]\\n| [[C++]], [[Wolfram Language]], [[CUDA]]\\n| [[Wolfram Language]]\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>http://resources.wolframcloud.com/NeuralNetRepository</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Depends|Under Development}}\\n|\\n|-\\n|[https://ver.ai VerAI]\\n|VerAI\\n| {{Proprietary}}\\n| {{No}}\\n|[[Linux]], [[Web application|Web-based]]\\n|[[C++]],[[Python (programming language)|Python]], [[Go (programming language)|Go]], [[Angular (application platform)|Angular]]\\n|[[Graphical user interface]], [[Command-line interface|cli]]\\n| {{No}}\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|\\n|}\\n\\n{{notelist}}\\n\\n==Related software==\\n* [[Neural Engineering Object]] (NENGO) – A graphical and scripting software for simulating large-scale neural systems\\n* [[Numenta Platform for Intelligent Computing]] – Numenta\\'s open source implementation of their [[hierarchical temporal memory]] model\\n\\n==See also==\\n*[[Comparison of numerical analysis software]]\\n*[[Comparison of statistical packages]]\\n*[[List of datasets for machine learning research]]\\n*[[List of numerical analysis software]]\\n\\n==References==\\n{{reflist|33em}}\\n\\n[[Category:Applied machine learning]]\\n[[Category:Comparisons of mathematical software|Deep learning frameworks]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wiki_xml('Comparison of deep learning software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
